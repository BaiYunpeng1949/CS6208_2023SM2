{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMg8wCzL10JKFa9FhYEILnr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":131,"metadata":{"id":"2zIb9gOqp56k","executionInfo":{"status":"ok","timestamp":1680936641236,"user_tz":-480,"elapsed":558,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}}},"outputs":[],"source":["import torch\n","torchversion = torch.__version__"]},{"cell_type":"code","source":["torchversion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"BiBMhNZGrdzX","executionInfo":{"status":"ok","timestamp":1680936641923,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"78804596-6b79-4377-df51-b4acf8c5edd4"},"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Visualization\n","import networkx as nx\n","import matplotlib.pyplot as plt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-mKEtJHifgb","executionInfo":{"status":"ok","timestamp":1680936660691,"user_tz":-480,"elapsed":18773,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"759f0735-50c5-404e-a58c-5d41e3dacc01"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["#@title Load Dataset - ENZMES\n","from torch_geometric.datasets import TUDataset, GNNBenchmarkDataset, Planetoid\n","\n","dataset = TUDataset(root='.', name='ENZYMES').shuffle()\n","# dataset = GNNBenchmarkDataset(root='.', name='MNIST').shuffle()   # The large dataset MINIST 100 epoches take over 8 hours\n","\n","# Print information about the dataset\n","print(f'Dataset: {dataset}')\n","print('-------------------')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of nodes: {dataset[0].x.shape[0]}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oi6xPICVilAV","executionInfo":{"status":"ok","timestamp":1680936660692,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"a9a22b66-1358-423b-ff0a-a5f49af48b6c"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset: ENZYMES(600)\n","-------------------\n","Number of graphs: 600\n","Number of nodes: 18\n","Number of features: 3\n","Number of classes: 6\n"]}]},{"cell_type":"code","source":["#@title Data split\n","from torch_geometric.loader import DataLoader\n","\n","# Create training, validation, and test sets\n","train_dataset = dataset[:int(len(dataset)*0.8)]\n","val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n","test_dataset  = dataset[int(len(dataset)*0.9):]\n","\n","print(f'Training set   = {len(train_dataset)} graphs')\n","print(f'Validation set = {len(val_dataset)} graphs')\n","print(f'Test set       = {len(test_dataset)} graphs')\n","\n","# Create mini-batches\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print('\\nTrain loader:')\n","for i, subgraph in enumerate(train_loader):\n","    print(f' - Subgraph {i}: {subgraph}')\n","\n","print('\\nValidation loader:')\n","for i, subgraph in enumerate(val_loader):\n","    print(f' - Subgraph {i}: {subgraph}')\n","\n","print('\\nTest loader:')\n","for i, subgraph in enumerate(test_loader):\n","    print(f' - Subgraph {i}: {subgraph}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-Lxeq_FinSX","executionInfo":{"status":"ok","timestamp":1680936660692,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"abd3a879-6fe7-4180-d5b3-f6ac1ccde9d7"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set   = 480 graphs\n","Validation set = 60 graphs\n","Test set       = 60 graphs\n","\n","Train loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 3802], x=[977, 3], y=[32], batch=[977], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 4162], x=[1063, 3], y=[32], batch=[1063], ptr=[33])\n"," - Subgraph 2: DataBatch(edge_index=[2, 4136], x=[1141, 3], y=[32], batch=[1141], ptr=[33])\n"," - Subgraph 3: DataBatch(edge_index=[2, 3656], x=[949, 3], y=[32], batch=[949], ptr=[33])\n"," - Subgraph 4: DataBatch(edge_index=[2, 3782], x=[1059, 3], y=[32], batch=[1059], ptr=[33])\n"," - Subgraph 5: DataBatch(edge_index=[2, 3968], x=[1090, 3], y=[32], batch=[1090], ptr=[33])\n"," - Subgraph 6: DataBatch(edge_index=[2, 3830], x=[981, 3], y=[32], batch=[981], ptr=[33])\n"," - Subgraph 7: DataBatch(edge_index=[2, 4240], x=[1087, 3], y=[32], batch=[1087], ptr=[33])\n"," - Subgraph 8: DataBatch(edge_index=[2, 4058], x=[1077, 3], y=[32], batch=[1077], ptr=[33])\n"," - Subgraph 9: DataBatch(edge_index=[2, 3942], x=[1010, 3], y=[32], batch=[1010], ptr=[33])\n"," - Subgraph 10: DataBatch(edge_index=[2, 3848], x=[1034, 3], y=[32], batch=[1034], ptr=[33])\n"," - Subgraph 11: DataBatch(edge_index=[2, 3542], x=[954, 3], y=[32], batch=[954], ptr=[33])\n"," - Subgraph 12: DataBatch(edge_index=[2, 3730], x=[949, 3], y=[32], batch=[949], ptr=[33])\n"," - Subgraph 13: DataBatch(edge_index=[2, 3958], x=[1031, 3], y=[32], batch=[1031], ptr=[33])\n"," - Subgraph 14: DataBatch(edge_index=[2, 4092], x=[1070, 3], y=[32], batch=[1070], ptr=[33])\n","\n","Validation loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 4410], x=[1166, 3], y=[32], batch=[1166], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 3038], x=[779, 3], y=[28], batch=[779], ptr=[29])\n","\n","Test loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 4482], x=[1173, 3], y=[32], batch=[1173], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 3888], x=[990, 3], y=[28], batch=[990], ptr=[29])\n"]}]},{"cell_type":"code","source":["#@title GNNs\n","from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout, LeakyReLU\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, GraphSAGE, GINConv, SAGEConv\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","from torch_scatter import scatter_add\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, dim_h):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_node_features, dim_h)\n","        self.conv2 = GCNConv(dim_h, dim_h)\n","        self.lin = Linear(dim_h, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch): \n","        h = self.conv1(x, edge_index)\n","        h = h.relu()\n","        h = self.conv2(h, edge_index)\n","        h = h.relu()\n","\n","        hG = global_mean_pool(h, batch)\n","\n","        h = F.dropout(hG, p=0.2, training=self.training)\n","        h = self.lin(h)\n","        \n","        return hG, F.log_softmax(h, dim=1)\n","\n","class GraphSAGENet(torch.nn.Module):\n","    def __init__(self, dim_h):\n","        super(GraphSAGENet, self).__init__()\n","        self.conv1 = SAGEConv(dataset.num_node_features, dim_h, aggr='mean')\n","        self.conv2 = SAGEConv(dim_h, dim_h, aggr='mean')\n","        self.lin = Linear(dim_h, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        h = self.conv1(x, edge_index)\n","        h = h.relu()\n","        h = self.conv2(h, edge_index)\n","        h = h.relu()\n","\n","        hG = global_mean_pool(h, batch)\n","\n","        h = F.dropout(hG, p=0.2, training=self.training)\n","        h = self.lin(h)\n","        \n","        return hG, torch.log(F.softmax(h, dim=1))\n","\n","class GIN(torch.nn.Module):\n","    def __init__(self, dim_h, num_layers=5):\n","        super(GIN, self).__init__()\n","        self.num_layers = num_layers\n","        self.mlps = torch.nn.ModuleList()\n","        for i in range(num_layers):\n","            if i == 0:\n","                self.mlps.append(Sequential(Linear(dataset.num_node_features, dim_h),\n","                                            BatchNorm1d(dim_h), LeakyReLU(),\n","                                            Linear(dim_h, dim_h), LeakyReLU()))\n","            else:\n","                self.mlps.append(Sequential(Linear(dim_h, dim_h),\n","                                            BatchNorm1d(dim_h), LeakyReLU(),\n","                                            Linear(dim_h, dim_h), LeakyReLU()))\n","        self.lin1 = Linear(dim_h*num_layers, dim_h*num_layers)\n","        self.lin2 = Linear(dim_h*num_layers, dim_h*num_layers)\n","        self.lin3 = Linear(dim_h*num_layers, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","\n","        h_list = []\n","        for i in range(self.num_layers):\n","            if i == 0:\n","                h_list.append(self.mlps[i](x))\n","            else:\n","                h_list.append(self.mlps[i](h_list[i-1]))\n","\n","        h_list = [scatter_add(h, batch, dim=0) for h in h_list]\n","        \n","        h = torch.cat(h_list, dim=1)\n","\n","        h = self.lin1(h)\n","        h = F.leaky_relu(h, negative_slope=0.1)\n","        h = F.dropout(h, p=0.2, training=self.training)\n","        h = self.lin2(h)\n","        h = F.leaky_relu(h, negative_slope=0.1)\n","        h = F.dropout(h, p=0.2, training=self.training)\n","        h = self.lin3(h)\n","        return h, torch.log(F.softmax(h, dim=1))\n","\n","gcn = GCN(dim_h=32)\n","graphsagenet = GraphSAGENet(dim_h=32)\n","gin = GIN(dim_h=32)"],"metadata":{"id":"z3fVUUs5iqX5","executionInfo":{"status":"ok","timestamp":1680936660692,"user_tz":-480,"elapsed":4,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["#@title Train models\n","def train(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                      lr=0.01,\n","                                      weight_decay=0.01)\n","    epochs = 100\n","\n","    model.train()\n","    for epoch in range(epochs+1):\n","      total_loss = 0\n","      acc = 0\n","      val_loss = 0\n","      val_acc = 0\n","\n","      # Train on batches\n","      for data in loader:\n","        optimizer.zero_grad()\n","        _, out = model(data.x, data.edge_index, data.batch)\n","        loss = criterion(out, data.y)\n","        total_loss += loss / len(loader)\n","        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        val_loss, val_acc = test(model, val_loader)\n","\n","    # Print metrics every 10 epochs\n","    if(epoch % 10 == 0):\n","        print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n","              f'| Train Acc: {acc*100:>5.2f}% '\n","              f'| Val Loss: {val_loss:.2f} '\n","              f'| Val Acc: {val_acc*100:.2f}%')\n","          \n","    test_loss, test_acc = test(model, test_loader)\n","    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n","    \n","    return model\n","\n","def test(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    model.eval()\n","    loss = 0\n","    acc = 0\n","\n","    for data in loader:\n","      _, out = model(data.x, data.edge_index, data.batch)\n","      loss += criterion(out, data.y) / len(loader)\n","      acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","\n","    return loss, acc\n","\n","def accuracy(pred_y, y):\n","    \"\"\"Calculate accuracy.\"\"\"\n","    return ((pred_y == y).sum() / len(y)).item()\n","\n","gcn = train(gcn, train_loader)\n","graphsagenet = train(graphsagenet, train_loader)\n","gin = train(gin, train_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ule-woZjkkoL","executionInfo":{"status":"ok","timestamp":1680936780486,"user_tz":-480,"elapsed":119798,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"90dc2082-f8a6-4184-bd1e-ac22b0fca672"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 100 | Train Loss: 1.79 | Train Acc: 17.29% | Val Loss: 1.79 | Val Acc: 22.32%\n","Test Loss: 1.80 | Test Acc: 6.47%\n","Epoch 100 | Train Loss: 1.78 | Train Acc: 22.29% | Val Loss: 1.77 | Val Acc: 26.56%\n","Test Loss: 1.80 | Test Acc: 8.04%\n","Epoch 100 | Train Loss: 1.76 | Train Acc: 21.25% | Val Loss: 1.79 | Val Acc: 20.09%\n","Test Loss: 1.75 | Test Acc: 21.88%\n"]}]},{"cell_type":"code","source":["#@title Test and compare - GIN outperformed GCN and GraphSAGE\n","gcn.eval()\n","graphsagenet.eval()\n","gin.eval()\n","acc_gcn = 0\n","acc_graphSAGE = 0\n","acc_gin = 0\n","\n","for data in test_loader:\n","    # Get classifications\n","    _, out_gcn = gcn(data.x, data.edge_index, data.batch)\n","    _, out_graphSAGE = graphsagenet(data.x, data.edge_index, data.batch)\n","    _, out_gin = gin(data.x, data.edge_index, data.batch)\n","\n","    # Calculate accuracy scores\n","    acc_gcn += accuracy(out_gcn.argmax(dim=1), data.y) / len(test_loader)\n","    acc_graphSAGE += accuracy(out_graphSAGE.argmax(dim=1), data.y) / len(test_loader)\n","    acc_gin += accuracy(out_gin.argmax(dim=1), data.y) / len(test_loader)\n","\n","# Print results\n","print(f'GCN accuracy:     {acc_gcn*100:.2f}%')\n","print(f'GraphSAGE accuracy:     {acc_graphSAGE*100:.2f}%')\n","print(f'GIN accuracy:     {acc_gin*100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiMHSq6CkAWC","executionInfo":{"status":"ok","timestamp":1680936780488,"user_tz":-480,"elapsed":27,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"88d4b4ca-14a8-4811-a6f5-a750368a1d8a"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["GCN accuracy:     6.47%\n","GraphSAGE accuracy:     8.04%\n","GIN accuracy:     21.88%\n"]}]}]}