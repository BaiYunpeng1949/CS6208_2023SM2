{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWDOHmc3WbAwJs4Fki8enE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":179,"metadata":{"id":"2zIb9gOqp56k","executionInfo":{"status":"ok","timestamp":1680939382663,"user_tz":-480,"elapsed":428,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}}},"outputs":[],"source":["import torch\n","torchversion = torch.__version__"]},{"cell_type":"code","source":["torchversion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"BiBMhNZGrdzX","executionInfo":{"status":"ok","timestamp":1680939383265,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"8e72890d-1e50-4446-c2d1-52677895af83"},"execution_count":180,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":180}]},{"cell_type":"code","source":["# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Visualization\n","import networkx as nx\n","import matplotlib.pyplot as plt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-mKEtJHifgb","executionInfo":{"status":"ok","timestamp":1680939401701,"user_tz":-480,"elapsed":18440,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"fbb78b3b-3185-405b-a752-eb0cb3ebb784"},"execution_count":181,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["##Paper Review Code: HOW POWERFUL ARE GRAPH NEURAL NETWORKS?"],"metadata":{"id":"F6jWthAKqPqA"}},{"cell_type":"code","source":["#@title Load Dataset - ENZMES\n","from torch_geometric.datasets import TUDataset, GNNBenchmarkDataset, Planetoid\n","\n","dataset = TUDataset(root='.', name='PROTEINS').shuffle()             # You may also use paper's dataset, such as PROTEINS ENZYMES for test\n","# dataset = GNNBenchmarkDataset(root='.', name='MNIST').shuffle()   # The large dataset MINIST 100 epoches take over 8 hours to train\n","\n","# Print information about the dataset\n","print(f'Dataset: {dataset}')\n","print('-------------------')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of nodes: {dataset[0].x.shape[0]}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oi6xPICVilAV","executionInfo":{"status":"ok","timestamp":1680939401701,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"a53d5ef4-95f5-407e-bbf3-81550aa3e832"},"execution_count":182,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset: PROTEINS(1113)\n","-------------------\n","Number of graphs: 1113\n","Number of nodes: 36\n","Number of features: 3\n","Number of classes: 2\n"]}]},{"cell_type":"code","source":["#@title Data split\n","from torch_geometric.loader import DataLoader\n","\n","# Create training, validation, and test sets\n","train_dataset = dataset[:int(len(dataset)*0.8)]\n","val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n","test_dataset  = dataset[int(len(dataset)*0.9):]\n","\n","print(f'Training set   = {len(train_dataset)} graphs')\n","print(f'Validation set = {len(val_dataset)} graphs')\n","print(f'Test set       = {len(test_dataset)} graphs')\n","\n","# Create mini-batches\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print('\\nTrain loader:')\n","for i, subgraph in enumerate(train_loader):\n","    print(f' - Subgraph {i}: {subgraph}')\n","\n","print('\\nValidation loader:')\n","for i, subgraph in enumerate(val_loader):\n","    print(f' - Subgraph {i}: {subgraph}')\n","\n","print('\\nTest loader:')\n","for i, subgraph in enumerate(test_loader):\n","    print(f' - Subgraph {i}: {subgraph}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-Lxeq_FinSX","executionInfo":{"status":"ok","timestamp":1680939402692,"user_tz":-480,"elapsed":995,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"eec4026b-cbd4-4484-bc3a-741da6ecc68c"},"execution_count":183,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set   = 890 graphs\n","Validation set = 111 graphs\n","Test set       = 112 graphs\n","\n","Train loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 3498], x=[1013, 3], y=[32], batch=[1013], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 5784], x=[1613, 3], y=[32], batch=[1613], ptr=[33])\n"," - Subgraph 2: DataBatch(edge_index=[2, 5260], x=[1415, 3], y=[32], batch=[1415], ptr=[33])\n"," - Subgraph 3: DataBatch(edge_index=[2, 4954], x=[1274, 3], y=[32], batch=[1274], ptr=[33])\n"," - Subgraph 4: DataBatch(edge_index=[2, 3488], x=[948, 3], y=[32], batch=[948], ptr=[33])\n"," - Subgraph 5: DataBatch(edge_index=[2, 3980], x=[1068, 3], y=[32], batch=[1068], ptr=[33])\n"," - Subgraph 6: DataBatch(edge_index=[2, 2920], x=[792, 3], y=[32], batch=[792], ptr=[33])\n"," - Subgraph 7: DataBatch(edge_index=[2, 5434], x=[1421, 3], y=[32], batch=[1421], ptr=[33])\n"," - Subgraph 8: DataBatch(edge_index=[2, 5378], x=[1497, 3], y=[32], batch=[1497], ptr=[33])\n"," - Subgraph 9: DataBatch(edge_index=[2, 4210], x=[1091, 3], y=[32], batch=[1091], ptr=[33])\n"," - Subgraph 10: DataBatch(edge_index=[2, 5850], x=[1514, 3], y=[32], batch=[1514], ptr=[33])\n"," - Subgraph 11: DataBatch(edge_index=[2, 4376], x=[1165, 3], y=[32], batch=[1165], ptr=[33])\n"," - Subgraph 12: DataBatch(edge_index=[2, 3738], x=[957, 3], y=[32], batch=[957], ptr=[33])\n"," - Subgraph 13: DataBatch(edge_index=[2, 4332], x=[1205, 3], y=[32], batch=[1205], ptr=[33])\n"," - Subgraph 14: DataBatch(edge_index=[2, 5402], x=[1485, 3], y=[32], batch=[1485], ptr=[33])\n"," - Subgraph 15: DataBatch(edge_index=[2, 5072], x=[1309, 3], y=[32], batch=[1309], ptr=[33])\n"," - Subgraph 16: DataBatch(edge_index=[2, 4766], x=[1225, 3], y=[32], batch=[1225], ptr=[33])\n"," - Subgraph 17: DataBatch(edge_index=[2, 4668], x=[1210, 3], y=[32], batch=[1210], ptr=[33])\n"," - Subgraph 18: DataBatch(edge_index=[2, 4600], x=[1252, 3], y=[32], batch=[1252], ptr=[33])\n"," - Subgraph 19: DataBatch(edge_index=[2, 4354], x=[1208, 3], y=[32], batch=[1208], ptr=[33])\n"," - Subgraph 20: DataBatch(edge_index=[2, 4804], x=[1310, 3], y=[32], batch=[1310], ptr=[33])\n"," - Subgraph 21: DataBatch(edge_index=[2, 4826], x=[1343, 3], y=[32], batch=[1343], ptr=[33])\n"," - Subgraph 22: DataBatch(edge_index=[2, 3710], x=[1009, 3], y=[32], batch=[1009], ptr=[33])\n"," - Subgraph 23: DataBatch(edge_index=[2, 6334], x=[1552, 3], y=[32], batch=[1552], ptr=[33])\n"," - Subgraph 24: DataBatch(edge_index=[2, 3898], x=[1088, 3], y=[32], batch=[1088], ptr=[33])\n"," - Subgraph 25: DataBatch(edge_index=[2, 3988], x=[1107, 3], y=[32], batch=[1107], ptr=[33])\n"," - Subgraph 26: DataBatch(edge_index=[2, 4766], x=[1332, 3], y=[32], batch=[1332], ptr=[33])\n"," - Subgraph 27: DataBatch(edge_index=[2, 3582], x=[955, 3], y=[26], batch=[955], ptr=[27])\n","\n","Validation loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 5534], x=[1509, 3], y=[32], batch=[1509], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 4966], x=[1363, 3], y=[32], batch=[1363], ptr=[33])\n"," - Subgraph 2: DataBatch(edge_index=[2, 5070], x=[1353, 3], y=[32], batch=[1353], ptr=[33])\n"," - Subgraph 3: DataBatch(edge_index=[2, 1870], x=[479, 3], y=[15], batch=[479], ptr=[16])\n","\n","Test loader:\n"," - Subgraph 0: DataBatch(edge_index=[2, 5396], x=[1429, 3], y=[32], batch=[1429], ptr=[33])\n"," - Subgraph 1: DataBatch(edge_index=[2, 5366], x=[1440, 3], y=[32], batch=[1440], ptr=[33])\n"," - Subgraph 2: DataBatch(edge_index=[2, 3600], x=[970, 3], y=[32], batch=[970], ptr=[33])\n"," - Subgraph 3: DataBatch(edge_index=[2, 2314], x=[570, 3], y=[16], batch=[570], ptr=[17])\n"]}]},{"cell_type":"code","source":["#@title GNNs\n","from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout, LeakyReLU\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, GraphSAGE, GINConv, SAGEConv\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","from torch_scatter import scatter_add\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, dim_h):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_node_features, dim_h)\n","        self.conv2 = GCNConv(dim_h, dim_h)\n","        self.lin = Linear(dim_h, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch): \n","        h = self.conv1(x, edge_index)\n","        h = h.relu()\n","        h = self.conv2(h, edge_index)\n","        h = h.relu()\n","\n","        hG = global_mean_pool(h, batch)\n","\n","        h = F.dropout(hG, p=0.2, training=self.training)\n","        h = self.lin(h)\n","        \n","        return hG, F.log_softmax(h, dim=1)\n","\n","\n","class GraphSAGENet(torch.nn.Module):\n","    def __init__(self, dim_h):\n","        super(GraphSAGENet, self).__init__()\n","        self.conv1 = SAGEConv(dataset.num_node_features, dim_h, aggr='mean')\n","        self.conv2 = SAGEConv(dim_h, dim_h, aggr='mean')\n","        self.lin = Linear(dim_h, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        h = self.conv1(x, edge_index)\n","        h = h.relu()\n","        h = self.conv2(h, edge_index)\n","        h = h.relu()\n","\n","        hG = global_mean_pool(h, batch)\n","\n","        h = F.dropout(hG, p=0.2, training=self.training)\n","        h = self.lin(h)\n","        \n","        return hG, torch.log(F.softmax(h, dim=1))\n","        \n","\n","class GIN(torch.nn.Module):\n","    def __init__(self, dim_h, num_layers=5):\n","        super(GIN, self).__init__()\n","        self.num_layers = num_layers\n","        self.mlps = torch.nn.ModuleList()\n","        for i in range(num_layers):\n","            if i == 0:\n","                self.mlps.append(Sequential(Linear(dataset.num_node_features, dim_h),\n","                                            BatchNorm1d(dim_h), LeakyReLU(),\n","                                            Linear(dim_h, dim_h), LeakyReLU()))\n","            else:\n","                self.mlps.append(Sequential(Linear(dim_h, dim_h),\n","                                            BatchNorm1d(dim_h), LeakyReLU(),\n","                                            Linear(dim_h, dim_h), LeakyReLU()))\n","        self.lin1 = Linear(dim_h*num_layers, dim_h*num_layers)\n","        self.lin2 = Linear(dim_h*num_layers, dim_h*num_layers)\n","        self.lin3 = Linear(dim_h*num_layers, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","\n","        h_list = []\n","        for i in range(self.num_layers):\n","            if i == 0:\n","                h_list.append(self.mlps[i](x))\n","            else:\n","                h_list.append(self.mlps[i](h_list[i-1]))\n","\n","        h_list = [scatter_add(h, batch, dim=0) for h in h_list]\n","        \n","        h = torch.cat(h_list, dim=1)\n","\n","        h = self.lin1(h)\n","        h = F.leaky_relu(h, negative_slope=0.1)\n","        h = F.dropout(h, p=0.2, training=self.training)\n","        h = self.lin2(h)\n","        h = F.leaky_relu(h, negative_slope=0.1)\n","        h = F.dropout(h, p=0.2, training=self.training)\n","        h = self.lin3(h)\n","        return h, torch.log(F.softmax(h, dim=1))\n","\n","dim_h = 32\n","gcn = GCN(dim_h=dim_h)\n","graphsagenet = GraphSAGENet(dim_h=dim_h)\n","gin = GIN(dim_h=dim_h)"],"metadata":{"id":"z3fVUUs5iqX5","executionInfo":{"status":"ok","timestamp":1680939402692,"user_tz":-480,"elapsed":2,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}}},"execution_count":184,"outputs":[]},{"cell_type":"code","source":["#@title Train models\n","def train(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                      lr=0.01,\n","                                      weight_decay=0.01)\n","    epochs = 100\n","\n","    model.train()\n","    for epoch in range(epochs+1):\n","      total_loss = 0\n","      acc = 0\n","      val_loss = 0\n","      val_acc = 0\n","\n","      # Train on batches\n","      for data in loader:\n","        optimizer.zero_grad()\n","        _, out = model(data.x, data.edge_index, data.batch)\n","        loss = criterion(out, data.y)\n","        total_loss += loss / len(loader)\n","        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        val_loss, val_acc = test(model, val_loader)\n","\n","    # Print metrics every 10 epochs\n","    if(epoch % 10 == 0):\n","        print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n","              f'| Train Acc: {acc*100:>5.2f}% '\n","              f'| Val Loss: {val_loss:.2f} '\n","              f'| Val Acc: {val_acc*100:.2f}%')\n","          \n","    test_loss, test_acc = test(model, test_loader)\n","    print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')\n","    \n","    return model\n","\n","def test(model, loader):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    model.eval()\n","    loss = 0\n","    acc = 0\n","\n","    for data in loader:\n","      _, out = model(data.x, data.edge_index, data.batch)\n","      loss += criterion(out, data.y) / len(loader)\n","      acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n","\n","    return loss, acc\n","\n","def accuracy(pred_y, y):\n","    \"\"\"Calculate accuracy.\"\"\"\n","    return ((pred_y == y).sum() / len(y)).item()\n","\n","gcn = train(gcn, train_loader)\n","graphsagenet = train(graphsagenet, train_loader)\n","gin = train(gin, train_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ule-woZjkkoL","executionInfo":{"status":"ok","timestamp":1680940045075,"user_tz":-480,"elapsed":642385,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"8fdbec67-9217-4036-a959-004e215bb37e"},"execution_count":185,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 100 | Train Loss: 0.68 | Train Acc: 58.37% | Val Loss: 0.68 | Val Acc: 59.43%\n","Test Loss: 0.65 | Test Acc: 65.62%\n","Epoch 100 | Train Loss: 0.66 | Train Acc: 65.73% | Val Loss: 0.64 | Val Acc: 68.44%\n","Test Loss: 0.64 | Test Acc: 66.41%\n","Epoch 100 | Train Loss: 0.57 | Train Acc: 70.94% | Val Loss: 0.49 | Val Acc: 80.83%\n","Test Loss: 0.53 | Test Acc: 72.66%\n"]}]},{"cell_type":"code","source":["#@title Test and compare - GIN outperformed GCN and GraphSAGE\n","gcn.eval()\n","graphsagenet.eval()\n","gin.eval()\n","acc_gcn = 0\n","acc_graphsage = 0\n","acc_gin = 0\n","\n","for data in test_loader:\n","    # Get classifications\n","    _, out_gcn = gcn(data.x, data.edge_index, data.batch)\n","    _, out_graphsage = graphsagenet(data.x, data.edge_index, data.batch)\n","    _, out_gin = gin(data.x, data.edge_index, data.batch)\n","\n","    # Calculate accuracy scores\n","    acc_gcn += accuracy(out_gcn.argmax(dim=1), data.y) / len(test_loader)\n","    acc_graphsage += accuracy(out_graphsage.argmax(dim=1), data.y) / len(test_loader)\n","    acc_gin += accuracy(out_gin.argmax(dim=1), data.y) / len(test_loader)\n","\n","# Print results\n","print(f'GCN accuracy:     {acc_gcn*100:.2f}%')\n","print(f'GraphSAGE accuracy:     {acc_graphsage*100:.2f}%')\n","print(f'GIN accuracy:     {acc_gin*100:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiMHSq6CkAWC","executionInfo":{"status":"ok","timestamp":1680940391985,"user_tz":-480,"elapsed":3,"user":{"displayName":"Yunpeng Bai","userId":"15683025891379390348"}},"outputId":"f343bb8f-197c-493b-a898-d6dc19a70158"},"execution_count":190,"outputs":[{"output_type":"stream","name":"stdout","text":["GCN accuracy:     65.62%\n","GraphSAGE accuracy:     66.41%\n","GIN accuracy:     72.66%\n"]}]}]}